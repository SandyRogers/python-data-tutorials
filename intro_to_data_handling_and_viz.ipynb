{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e8d5e80-f493-4da6-a185-80927a4cd74a",
   "metadata": {},
   "source": [
    "# Introduction to data handling and visualisation with python\n",
    "\n",
    "This is a Jupyter Notebook, designed to introduce some popular and useful approaches and libraries for data handling and visualisation in Python and the Python ecosystem.\n",
    "\n",
    "We will be using [pandas](https://pandas.pydata.org/) library for the data handling parts, and the [seaborn](https://seaborn.pydata.org/) library for visualisation. There are altneratives, but these two are great options if you want to \"just learn one thing\".\n",
    "\n",
    "## Sections\n",
    "- Python and duck typing\n",
    "- The Python data ecosystem:\n",
    "  - Reading data\n",
    "  - Manipulating (anonymising) and parsing data\n",
    "  - Saving data\n",
    "  - Joining dataframes\n",
    "- Visualising data\n",
    "  - Seaborn for quick but nice figures\n",
    "  - Time-series analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc4805-5944-4cdb-bb7c-7d8931d95d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e288ae-7f8f-431f-882c-140fff4b3645",
   "metadata": {},
   "source": [
    "## Python and duck typing\n",
    "\n",
    "Python is \"duck typed\" (\"if it looks like a duck and quacks like a duck... its a duck!\").\n",
    "That means you don't need to _declare_ the type of a variable, it is inferred.\n",
    "(Note that in modern Python you CAN add a \"type hint\", and they are wonderful, but they are mostly used to help readability and catch some bugs.)\n",
    "\n",
    "Python is unusual in that you can make an iterable `List` of varied types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d76be-3b52-4bfc-a827-f3411a31f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_strange_list = [\"hello\", 42, pd.DataFrame, [1,2,3], {\"this\": \"that\"}]\n",
    "\n",
    "my_strange_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20785d-0fdc-4ec5-a879-5ba47b2c5b01",
   "metadata": {},
   "source": [
    "Note that each element in this List has a different type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe762a-a55c-417a-b833-621274db9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(element) for element in my_strange_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521efe9-ce12-45f7-b467-836699424ed0",
   "metadata": {},
   "source": [
    "(By the way, that `[thing for thing in things]` form of code is called a \"list comprehension\". They are very handy in Python for doing an inline loop or conditional.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6272a-aaf9-4c67-8a4e-28e2005e661a",
   "metadata": {},
   "source": [
    "In data analysis, most people are used to `Array`s rather than Pythonic `List`s.\n",
    "`Array`s tend to be fixed type, and a bit more like a mathematical vector.\n",
    "For instance consider this, and before you run it... what do you THINK the result should be?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db2a57-4136-47df-ae7a-61ea08506d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2,3] * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427fb9b-295b-4cdd-845b-8ccde583d53e",
   "metadata": {},
   "source": [
    "In the Python ecosystem, the most popular way to get a more \"normal\" `Array`, that works like in `R` etc, is to use `numpy`. `numpy` gives you an `Array` type that is very fast to do things with, since every element is known to be of the same type so a bunch of type-checking can be skipped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dab0e-3f5c-4db2-9e78-c4f2795298cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3]) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d793fde-ef14-4e96-94f4-236169805936",
   "metadata": {},
   "source": [
    "## Python's data ecosystem\n",
    "\n",
    "This is just one example of the ecosystem of libraries that can build upon Python's generic design and add data-handling focussed tooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1496a-dfc5-4925-84c5-1a198c95bdca",
   "metadata": {},
   "source": [
    "### Reading data\n",
    "\n",
    "For example, you CAN read data using Python's \"standard library\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4689e2-080f-4467-a86f-5714be659d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "my_data = []  # an empty list\n",
    "with open(\"people.tsv\") as my_csv_file:  # a file handler\n",
    "    my_csv_reader = csv.DictReader(my_csv_file, delimiter='\\t')  # from the python standard library, a way to read CSV files into dictionaries\n",
    "    for row in my_csv_reader:  # iterate over all lines in the TSV\n",
    "        my_data.append(row)\n",
    "\n",
    "my_data[:10] # the first 10 items in the list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a86514-c840-4fe9-9df4-631cc273c367",
   "metadata": {},
   "source": [
    "... but it is much less code to do this using the `pandas` (commonly shortened to `pd`) library, than is not part of the standard library either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae7f1f-ddeb-496a-b583-6d223740fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv(\"people.tsv\", sep=\"\\t\")\n",
    "my_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75c10b-0350-4459-899d-7f747df1c683",
   "metadata": {},
   "source": [
    "This object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6bde65-e00e-4e22-a95f-e9eb9881a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5c07c-6df0-4e49-a6cd-c774df6ceb44",
   "metadata": {},
   "source": [
    "is a `pandas` `DataFrame`. It is similar to data frames in other analytical / data science languages and tools.\n",
    "Specifically it is a great object for having tabular data (or higher-dimension structured data), especially when you've got named columns, differrent special data types like strings, numbers, and dates, and when you want to do tabular things like lookups, orderings, group-bys, and table-to-table JOINs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8040e-db39-489d-b28e-9cd7a69e8cfc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a8f08-11bc-4a23-a868-8ae4816c2e54",
   "metadata": {},
   "source": [
    "### Manipulating a dataframe: anonymising data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1c128-ae17-419c-a5ab-64917fca4526",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background-color:#e6f3ff;\n",
    "  border-left:6px solid #2196F3;\n",
    "  padding:10px 16px;\n",
    "  border-radius:6px;\n",
    "  font-size:14px;\n",
    "\">\n",
    " Task 1: anonymise that data frame.\n",
    "  We have research data about patients, and want to anonymise it. To do so at the very least we should (1) remove their names and replace them with patient identifiers, and (2) compress their dats of birth into less identifiable integer ages.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a040c73-9aaa-4694-ba91-3728b54a7106",
   "metadata": {},
   "source": [
    "**For the names:** consider that we may need to be able to join FURTHER data, by patient name, to this. So rather than anonymise, we can pseudononymise. One simple way is to make a `hash` of their name, such that it is very easy to turn another copy of that name in future data into the hash, but (relatively) hard to do the opposite.\n",
    "\n",
    "You can make a new column in a `pandas` `DataFrame`, that takes as input a single existing column, like this with the `.apply` method:\n",
    "\n",
    "```python\n",
    "def my_method(name):\n",
    "    # reverse the letters in name\n",
    "    # in reality use something cryptographic, like a method from \"hashlib\".\n",
    "    # bonus points for implementing that!\n",
    "    return name[::-1]  # python slices are defined like [0:10:-1] for elements 0 to 10 in reverse order\n",
    "\n",
    "my_data['identifier'] = my_data['name'].apply(my_method)\n",
    "```\n",
    "\n",
    "Lastly: \n",
    "- remember to actually remove the names! Look into the method `my_data.drop(columns=...)` to remove a column. Hint: check out the `inplace=` parameter.\n",
    "- \"index\" the dataframe by this new identifier, since the table is naturally keyed by it (each row is a person). To set the index of a `DataFrame`, look into the method `my_data.set_index(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfb15e-543c-4b62-968d-ee91fe248432",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.read_csv(\"people.tsv\", sep=\"\\t\")\n",
    "\n",
    "def pseudonymise_name(name: str):\n",
    "    # ... your code\n",
    "\n",
    "people['identifier'] = # ... your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0f179-3aca-4b92-a618-d683fc65262a",
   "metadata": {},
   "source": [
    "You should end up with a dataframe called `people` that looks like:\n",
    "\n",
    "| identifier | date_of_birth |\n",
    "| ---------- | ------------- |\n",
    "| abcd123456 | 10/28/1969    |\n",
    "| wxyz987654 | 12/07/1965    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b3f1b-bfde-441d-91a1-3e4ea77749c4",
   "metadata": {},
   "source": [
    "(The solution is in the collapsed cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997954f0-1533-48fc-9152-4ee2da821696",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "import hashlib\n",
    "\n",
    "people = pd.read_csv(\"people.tsv\", sep=\"\\t\")\n",
    "\n",
    "def pseudonymise_name(name: str):\n",
    "    return hashlib.md5(name.encode()).hexdigest()\n",
    "\n",
    "people[\"identifier\"] = people[\"name\"].apply(pseudonymise_name)\n",
    "people.drop(columns=[\"name\"], inplace=True)\n",
    "people.set_index(\"identifier\", inplace=True)\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800589b5-d1d2-44da-89ab-3c2af27bc587",
   "metadata": {},
   "source": [
    "**For the dates of birth:** \n",
    "First, we need to parse the dates. At the moment they are just arbitrary objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642784be-3e24-44c4-821c-923bf9fc3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "people.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbb9453-a079-42d6-bcf7-1798957e5564",
   "metadata": {},
   "source": [
    "...but Python, and pandas, have an actual `datetime` object for this, that helps disambiguate all the weirdness of dates and time intervals etc.\n",
    "\n",
    "The Python one is part of the standard library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbfd7e-5440-46de-8cf8-06f300f3b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "now = datetime.now()\n",
    "\n",
    "print(now)\n",
    "print(type(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac0813-5334-4d7f-8072-37aab71bf47e",
   "metadata": {},
   "source": [
    "So! We want to parse and coerce the dates of birth into datetimes, so that we can calculate their integer ages based on the `timedelta` between that date and `now`.\n",
    "\n",
    "This is so common that `Pandas` [provides a method](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html#pandas-to-datetime) for it: `pd.to_datetime(my_pandas_series)`.\n",
    "\n",
    "**Write code to overwrite the `people.date_of_birth` column to be parsed `datetime`s.\n",
    "Note that this CSV uses the bizarre \"middle-endian\" date format (i.e. month/day/year) common to the USA... not a nice ISO standard! So, you'll need to [provide a `format=` argument to tell `pd.to_datetime`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html#pandas-to-datetime) how to understand this insanity.**\n",
    "\n",
    "(Hint: `%d-%m-%Y` represents the format of a dd-mm-yyyy year like `24-10-2025`.)\n",
    "\n",
    "You may notice that the data includes some problems... we will fix those in a moment but check out the `errors=` parameter to find a way to coerce the dates into shape first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be9064-04b9-4a6f-9cb5-e7881a492f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "people.date_of_birth = # ... your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3fbb33-8481-4779-aea3-4e9435895bbc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "people.date_of_birth = pd.to_datetime(people.date_of_birth, format=\"%m/%d/%Y\", errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f984c-65e9-4ffc-9376-63c53a32ed9c",
   "metadata": {},
   "source": [
    "Now, if you managed to coerce those bad dates... you'll notice that they appear in the DataFrame with a strange symbol `NaT` (not a time). Let's just drop those data from our set. Again, this is such a common thing that `pandas` provides a method: `my_data.dropna(...)` (`dropna` means drop NAs, and NA means \"Not A\" - like \"Not A Number (NaN) etc). Check out the help for that method to see how to ONLY drop rows which have an NA in a subset of the columns (in our case, `date_of_birth`).\n",
    "\n",
    "Like earlier... you want to modify the existing dataframe, so check out the `inplace=` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1bc5aa-2ad1-4054-999b-dd22defbef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7b52c-359b-4890-bfa4-2b219acb89d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution \n",
    "people.dropna(subset=[\"date_of_birth\"], inplace=True)\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45590793-d8de-44de-8c62-f44a54f1e4e4",
   "metadata": {},
   "source": [
    "Finally, we can calculate their ages!\n",
    "\n",
    "Like earlier when we pseudonymised the names, pseudonymise their ages by first creating a new `people[\"age\"]` column, and then dropping the `date_of_birth` column.\n",
    "\n",
    "To calculate the age, you can just to normal arithmetic with the datetime objects. We calculated `now` earlier as the current date, so `now - <some date>` gives a `Timedelta`, which has a property `.days`. You can turn `.days` into years by just dividing and pretending leap years don't exist for our simple purposes. Finally, you can cast the floating point age to an integer by just wrapping it in `int(...)` – that's just standard Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34deb92-b91d-4aed-93bc-225c2a43521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "people['age'] = # your code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145cee0f-8967-4079-99f7-f2758d76b091",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "people['age'] = people.date_of_birth.apply(lambda dob: int((now - dob).days / 365))\n",
    " # by the way, a lambda is like an inline unnamed function, \n",
    "  # it just takes an argument (dob) and returns whatever the value after the colon is. handy!\n",
    "people.drop(columns=[\"date_of_birth\"], inplace=True)\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee04934-e20d-4e06-b755-e78060368854",
   "metadata": {},
   "outputs": [],
   "source": [
    "people.to_csv("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54815dd5-c1fd-4372-ad49-a2df55bbace0",
   "metadata": {},
   "source": [
    "### Saving dataframes\n",
    "\n",
    "You might want to save this dataframe back to a TSV file... like `anonymous_people.tsv`.\n",
    "\n",
    "To do, use to `.to_csv(...)` method on the `people` dataframe. Note that a TSV (Tab Separated Value) is often a better choice than a CSV (Comma Separated Value), but is so similar that you use the same method to write it. Just set the argument `sep='\\t'` (`sep` for seperator, and `\\t` is the control character for a tab, like `\\n` is a newline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843305c-d25b-4f6f-a229-9eedd73577d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "people.\n",
    "# your code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdf588-6c63-47b6-a9a2-f3d2de538de7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Joining dataframes\n",
    "\n",
    "Often you will have multiple datasets that need to be joined together, e.g. from multiple data sources or multi-omics results.\n",
    "Ocassionally this is concatenating dataframes \"row-wise\" (e.g. adding more people to the table), but more often is it \"column-wise\" (e.g. adding more data about each person).\n",
    "\n",
    "<div style=\"\n",
    "  background-color:#e6f3ff;\n",
    "  border-left:6px solid #2196F3;\n",
    "  padding:10px 16px;\n",
    "  border-radius:6px;\n",
    "  font-size:14px;\n",
    "\">\n",
    " Task 2: Join the `people` dataframe to a new dataframe read in from the measurements.tsv table.\n",
    "</div>\n",
    "\n",
    "Hints:\n",
    "- `measurements.tsv` can be read into a dataframe just like before.\n",
    "- `measurements` contains names... but remember we want to be pseudonymous so you'll need to convert names to identifiers exactly as before, so that the identifiers can be used to join the dataframes\n",
    "- there are multiple `measurement`s for each person! This means you **shouldn't** use the `identifier` as the `index` for the `measurements` dataframe, as it wouldn't be unique.\n",
    "- the method to join two dataframes is `people_measurements = measurements.join(people, on='identifier')`. The `on='identifier'` argument means that the index of `people` will be `join`ed `on`to the `identifier` column of `measurements`. By the way, this wouldn't be needed if the two dataframes were both indexed by the same identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935d3ca-f61b-4392-b257-5c1ca0ddb0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = # your code...\n",
    "people_measurements = # your code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42368e-6141-4978-b355-dde41c23ec20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "measurements = pd.read_csv(\"measurements.tsv\", sep=\"\\t\")\n",
    "measurements[\"identifier\"] = measurements.name.apply(pseudonymise_name)\n",
    "measurements.drop(columns=[\"name\"], inplace=True)\n",
    "people_measurements = measurements.join(people, on='identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e5512-4d53-4eb1-967d-2dd7c2e41fdb",
   "metadata": {},
   "source": [
    "You might notice from looking at the `people_measurements` dataframe that there are also some missing (`NaN`) weight measurements in there.\n",
    "\n",
    "Drop those dataframe rows like we did with the missing dates of birth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da5ff8-8f82-4961-9f74-04033c4ed351",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_measurements. # your code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e9641-d668-42d9-b276-c7c14f69711b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "people_measurements.dropna(subset=[\"weight_kg\"], inplace=True)\n",
    "people_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd561d-b716-4162-b616-888f1182c703",
   "metadata": {},
   "source": [
    "Lastly, we need to parse the dates as actual dates again. Interestingly, these dates are formatted in the little-endian sense of dd/mm/yyyy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc3fc5-909f-458b-bc1e-8fdd11bc9b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_measurements.date = pd.to_datetime(people_measurements.date, format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "people_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98cbb1-6ad3-48a1-9344-c823d1f1fa15",
   "metadata": {},
   "source": [
    "**All being well you now have a dataframe of 941 weight measurements, for about 100 people whose ages we know.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc97b261-0d37-42fd-bdc5-2a426374228e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualising data\n",
    "\n",
    "An obvious place to start here would be plotting weight vs age. For simple \"explorative\" visualisation like this, `pandas` actually provides built in plotting methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb5060-40b2-4d7d-9977-e592344aa4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_measurements.plot(x=\"age\", y=\"weight_kg\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e458b9-9e1d-4245-bb57-b9616ff1a7a9",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background-color:#e6f3ff;\n",
    "  border-left:6px solid #2196F3;\n",
    "  padding:10px 16px;\n",
    "  border-radius:6px;\n",
    "  font-size:14px;\n",
    "\">\n",
    " Task 3: Explore the different \"kind\"s of plot pandas lets you make.\n",
    "</div>\n",
    "Use the popup help (press shift-tab whilst your cursor is inside the `.plot(   )` argument list), or call `help(people_measurements.plot)`, or just [read the docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html#pandas-dataframe-plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eda7d3-049d-4ae4-bb55-d8788f7dcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_measurements.plot(  # ... your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e2372-a77c-4594-9afd-bd23fa038d39",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background-color:#e6f3ff;\n",
    "  border-left:6px solid #2196F3;\n",
    "  padding:10px 16px;\n",
    "  border-radius:6px;\n",
    "  font-size:14px;\n",
    "\">\n",
    " Are any of these useful? Are any of them... pretty?\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590cd0af-2eb3-4720-94b5-a7a87ef20bfd",
   "metadata": {},
   "source": [
    "#### Seaborn: a quick route to publication ready visualisation\n",
    "\n",
    "`Seaborn` (commonly shortened to `sns`) and `matplotlib`'s `pyplot` (commonly `plt`) are two widely used options for data visualisation. In general `seaborn` does a lot without much configuration, whereas `matplotlib` is lower level, more general and configurable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ad7a7-96fa-4386-b433-65394c554f1a",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background-color:#e6f3ff;\n",
    "  border-left:6px solid #2196F3;\n",
    "  padding:10px 16px;\n",
    "  border-radius:6px;\n",
    "  font-size:14px;\n",
    "\">\n",
    " Task 4: Use seaborn to make a \"jointplot\" showing the age–weight datapoints, a linear regression through the data, and the distribution of data independently across both the age and weight dimensions.\n",
    "</div>\n",
    "\n",
    "Hint: this is much easier than it sounds! Check out [the `seaborn` `jointplot` documentation](https://seaborn.pydata.org/generated/seaborn.jointplot.html#seaborn-jointplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c608e0-8253-4f7a-9999-a531dfa1c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17990250-859a-4188-a24c-fa7b792da0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns. # ... your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc8880-3b12-4638-9217-85ef270a24be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "g = sns.jointplot(\n",
    "    data=people_measurements,\n",
    "    x=\"age\", y=\"weight_kg\",\n",
    "    kind=\"reg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e7fa9c-19e1-4bfd-bb13-0f5068842a72",
   "metadata": {},
   "source": [
    "**Fancy a fun break?** Play around with the [aesthetics options for seaborn](https://seaborn.pydata.org/tutorial/aesthetics.html#controlling-figure-aesthetics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b79bda-f5ab-4ce0-8db8-8151827b2c0b",
   "metadata": {},
   "source": [
    "The reason we set the result of the `sns....` call to a variable (`g = `) is so that we can do more with it after creation.\n",
    "Remake your plot, but set the axis labels to nicer ones like \"Age in years\".\n",
    "Use the `g.set_axis_labels(...)` method for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3b819-ef16-4f9f-86d9-93574afe005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_axis_labels(  # ... your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad2803-e8fa-4ffb-8d51-921f4b133649",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "g = sns.jointplot(\n",
    "    data=people_measurements,\n",
    "    x=\"age\", y=\"weight_kg\",\n",
    "    kind=\"reg\",\n",
    ")\n",
    "g.set_axis_labels(xlabel=\"Age in years\", ylabel=\"Weight in KG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652b97b-a787-424e-b908-a7a3c7a3ff44",
   "metadata": {},
   "source": [
    "### Time-series analysis\n",
    "\n",
    "So far, we can see that our cohort increase slightly in weight with age (once reaching adulthood).\n",
    "But what about individuals? We have multiple weight measurements on different dates... so we can perform a time series analysis of the individuals.\n",
    "\n",
    "One way to do this is to group the dataframe by `identifier` (person), so that we get a group of that individual's weight rows, and also order by date, so that we can the time series in chronological order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51609d65-35cb-4f84-b7ac-39d33ea6f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_measurements.sort_values([\"identifier\", \"date\"], inplace=True)\n",
    "\n",
    "people_timeseries = people_measurements.groupby(\"identifier\")\n",
    "people_timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830348be-6f09-45a2-a715-6833e9c4c4c2",
   "metadata": {},
   "source": [
    "We see that this `people_timeseries` is a \"DataFrameGroupBy` object... this is hard to comprehend, until we iterate over the groups (well, just the first for now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e28d25-86b2-441d-9a8e-b99e6ad216de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_label, group_content in people_timeseries:\n",
    "    print(group_label)\n",
    "    print(group_content)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6792921-772f-4b81-9c8e-9e75a52846cb",
   "metadata": {},
   "source": [
    "So the `group_label` there is a person identifier, and the `group_content` is a small dataframe of just their weight measurements - i.e. a timeseries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c636f32e-adfb-46c3-aab5-6777e54ba2f1",
   "metadata": {},
   "source": [
    "We can of course plot this timeseries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75813d5f-6ff8-41ca-aec9-62c243766e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_identifier = people_measurements.identifier.iloc[0]  # by the way, .iloc[0] is a method to LOCate the item in a pandas object at Index 0\n",
    "first_person_timeseries = people_timeseries.get_group(first_person_identifier)\n",
    "first_person_timeseries.plot(x=\"date\", y=\"weight_kg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77295fd-e983-4feb-8ef4-3f66f4287c3f",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background-color:#e6f3ff;\n",
    "  border-left:6px solid #2196F3;\n",
    "  padding:10px 16px;\n",
    "  border-radius:6px;\n",
    "  font-size:14px;\n",
    "\">\n",
    " Task 5 (much harder!): Make a multi-panel plot with seaborn. Each panel should represent a 10-year age-band, and show a mean time-series of weight for people in that age band.\n",
    "</div>\n",
    "\n",
    "Steps and hints: \n",
    "- we will need to `groupby` BOTH a decadal \"age band\", AND e.g. what month the weight measurement happened in (so that individuals' timeseries can be aligned to some common timeline)\n",
    "- the decadal age bands can be calculated by defining a list of age `bins` `0, 10, 20....` and then using `pd.cut` to make a temporary column (i.e. there will be a bin value, for every person, like `(20, 30]` for person aged 22).\n",
    "- the monthly timeseries grouping can be done using a normal pandas [Grouper](https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html#pandas-grouper), alongwith a [frequency alias for \"the start of each month\"](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects).\n",
    "- dataframes can be grouped by multiple groupers, by giving a **list** to `.groupby`, instead of a single column name.\n",
    "- there is [a good example in the seaborn documentation of the actual visualisation](https://seaborn.pydata.org/examples/timeseries_facets.html#small-multiple-time-series)!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99be2df-d374-4c2f-863f-5f612eafd338",
   "metadata": {},
   "source": [
    "Step 1: grouping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe05cef-1b2c-4752-8968-5c793f9a144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins =  # your code...\n",
    "monthly_by_age_band = people_measurements.groupby([  # your code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ef8c1-06bf-49a5-9d1e-60cf6a0acb2e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "monthly_by_age_band = people_measurements.groupby([\n",
    "    pd.Grouper(key=\"date\", freq=\"MS\"),\n",
    "    pd.cut(people_measurements[\"age\"], bins=bins)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62869ff-a45d-4832-b150-8e83e9f7ffea",
   "metadata": {},
   "source": [
    "Step 2: calculate the mean weight each month, for the people in each age band. \n",
    "We can just select the `weight_kg` column from the grouped data and call `.mean()` on it... Pandas knows to apply that to each group.\n",
    "A somewhat unintuitive step is here is to call `reset_index`. This is quite common after you've done a bunch of grouping and aggregating in pandas... the goal is to just get back to a regular, single-indexed \"table-like\" dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99204d0b-7e0d-4a43-a239-865381b9ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_averages_by_age_band = monthly_by_age_band[\"weight_kg\"].mean().reset_index(name=\"avg_weight\")\n",
    "monthly_averages_by_age_band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184d380-0f5a-4578-aabe-3bbacbdcf62a",
   "metadata": {},
   "source": [
    "You should see that we've ended up with a table where we have a date column, for the first of each month, an age column which is a decadal age band, and the average weight of people in that cohort on the month.\n",
    "\n",
    "<div style=\"\n",
    "  background-color:#e6f3ff;\n",
    "  border-left:6px solid #2196F3;\n",
    "  padding:10px 16px;\n",
    "  border-radius:6px;\n",
    "  font-size:14px;\n",
    "\">\n",
    " Can you spot a slight interpretation problem with our logic here?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ad889-2996-4755-aeb6-262c864777fb",
   "metadata": {},
   "source": [
    "Step 3: plot each age band in a panel. We can use the `relplot` from `seaborn`, similar to the example in the seaborn documentation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae708e0-85ba-4fa9-b057-43327fa98716",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "# your code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eda95f-5454-4499-ba0a-065b2237c16e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "g = sns.relplot(\n",
    "    data = monthly_averages_by_age_band,\n",
    "    x=\"date\",\n",
    "    y=\"avg_weight\",\n",
    "    col=\"age\",\n",
    "    hue=\"age\",\n",
    "    kind=\"line\", palette=\"crest\", linewidth=4, zorder=5,\n",
    "    col_wrap=4, height=2, aspect=1.5, legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f40d1-cd95-45f8-8e37-cdc793811a66",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this notebook, you've learned why Python really needs to be extended with its ecosystem of libraries to do data analysis.\n",
    "Specifically, `pandas` gives Python support for `dataframe`s, which are the basis of a lot of scientific data handling.\n",
    "It can handle data parsing, manipulating (like making new columns algorithmically from existing ones), and joining multiple datasets together.\n",
    "`Pandas` also gives us some basic plotting, but for more advanced visualisations – and especially for jumping straight to fairly aesthetically satisfying figures – we are better adopting a library like `seaborn` (which, as you've seen, is compatible with `pandas` dataframes).\n",
    "\n",
    "We finished with some time-series analysis, using `pandas` sorting and grouping methods to multiply-group our dataset, and used a `relplot` to create a grid of figure subplots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
